{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Perguntas_ver1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaimovi/Analise-de-similaridade-de-Banco-de-Perguntas-por-metodos-NLP/blob/main/Perguntas_ver1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "8516e4cfe5225b5c02a18f2be3c31313249b24c3",
        "_cell_guid": "07597ed8-0117-4ce1-b5b4-725ae012da4e",
        "id": "sPPU2PoqPJgt"
      },
      "source": [
        "# 1.Apresentação\n",
        "##Este notebook estrutura todas as etapas de pre processamento necessárias e que deverão ser aplicadas, independente de qual modelo . Estabelecemos as etapas de transformação em caixa baixa, retirando stopwords, caracteres especiais e etc.Em seguida utilizamos ainda neste Notebook o método de comparação por bag of words, calculando os vetores das sentenças, limitando o número de linhas para análise, considerando a restrição de recursos computacionais do Colab. A opção então foi de não importar todas as linhas do Banco de perguntas proposto, com 170000 perguntas e apenas buscar similaridades com as primeiras 5000 perguntas.\n",
        "##Há ainda no mesmo banco de dados o cadastro de Listas de verificação armazenadas com 466000 perguntas, podemos identificar a dificuldade de uma trabalho manual com 5000 perguntas, quer seja com 170000 e então com 466000 , a importância que identificamos com os métodos apresentados na questão de Linguística e os processamentos pelos métodos deste notebook.\n",
        "##A segunda parte da prova de Conceito faz uso de modelos transformacionais, BERT e ELECTRA para consolidar as respostas encontradas na primeira parte e compararmos os resultados para diferentes abordagens de modelos NLP(processamento Neuro Linguístico).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD8MCn-ye43m"
      },
      "source": [
        "## 1.1 Conceito de Bag of Words:\n",
        "###Bag of Words (BOW) é um método para extrair recursos de documentos de texto. Esses recursos podem ser usados ​​para treinar algoritmos de aprendizado de máquina. Ele cria um vocabulário de todas as palavras exclusivas que ocorrem em todos os documentos do conjunto de treinamento.\n",
        "###Em termos simples, é uma coleção de palavras para representar uma frase com contagem de palavras e principalmente desconsiderando a ordem em que aparecem.\n",
        "###BOW é uma abordagem amplamente usada com:\n",
        "### Processamento de linguagem natural\n",
        "### Recuperação de informações de documentos\n",
        "### Classificações de documentos\n",
        "###Em um alto nível, envolve as seguintes etapas.\n",
        "![BOW.png](data:image/png;base64,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)\n",
        "\n",
        "###Os vetores gerados podem ser inseridos em seu algoritmo de aprendizado de máquina.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spXGWWhwpXjg"
      },
      "source": [
        "##1.2 Conceito de BERT:\n",
        " O modelo BERT foi proposto em BERT: Pré-treinamento de Transformadores Profundos Bidirecionais para Entendimento de Linguagem por Jacob Devlin, Ming-Wei Chang, Kenton Lee e Kristina Toutanova. É um transformador bidirecional pré-treinado usando uma combinação de objetivo de modelagem de linguagem mascarada e previsão da próxima frase em um grande corpus que compreende o Toronto Book Corpus e a Wikipedia.\n",
        " Um modelo de representação de linguagem denominado BERT, que significa Bidirectional Encoder Representations from Transformers. Ao contrário dos modelos de representação de linguagem recentes, o BERT é projetado para pré-treinar representações bidirecionais profundas de texto não rotulado, condicionando conjuntamente o contexto esquerdo e direito em todas as camadas. Como resultado, o modelo BERT pré-treinado pode ser ajustado com apenas uma camada de saída adicional para criar modelos de última geração para uma ampla gama de tarefas, como resposta a perguntas e inferência de linguagem, sem tarefas substanciais. modificações específicas da arquitetura.\n",
        " BERT é conceitualmente simples e empiricamente poderoso. Ele obtém novos resultados de última geração em onze tarefas de processamento de linguagem natural, incluindo aumentar a pontuação do GLUE para 80,5% (7,7% de melhoria absoluta), precisão MultiNLI para 86,7% (4,6% de melhoria absoluta), SQuAD v1.1 perguntas respondendo Teste F1 a 93,2 (melhoria absoluta de 1,5 pontos) e SQuAD v2.0 Teste F1 a 83,1 (melhoria absoluta de 5,1 pontos).\n",
        " Pontas:\n",
        "     O BERT foi treinado com os objetivos de modelagem de linguagem mascarada (MLM) e previsão de próxima frase (NSP). É eficiente na previsão de tokens mascarados e em NLU em geral, mas não é ideal para geração de texto.\n",
        "     Referência Bibliográfica:\n",
        " https://www.affde.com/pt/bert-explained-what-you-need-to-know-about-googles-new-algorithm.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoFSO0FHqskD"
      },
      "source": [
        "##1.3 Conceito de ELECTRA:\n",
        "\n",
        "ELECTRA é um novo método auto-supervisionado de aprendizagem e compreensão de linguagem natural desenvolvido pela IA do Google. ELECTRA significa “Aprendendo Eficientemente um Codificador que Classifica Substituições de Token com Precisão”, utilizando eficientemente os métodos do modelo LM (Modelagem de Linguagem) e Modelo MLM (Modelagem de Linguagem Mascarada). Os modelos ELECTRA são treinados para entender a diferença entre tokens de entrada “reais” e tokens de entrada “falsos”.\n",
        "Metodologia ELECTRA\n",
        "\n",
        "Os métodos disponíveis recentemente para treinamento são divididos em categorias: Modelos de primeira língua (LMs) como GPT que executam a tarefa da esquerda para a direita de maneiras unidirecionais e prevendo a próxima palavra de acordo com o contexto anterior. Segundo método executado por modelos de linguagem mascarada (MLMs), por ex. BERT, RoBERTa e ALBERT. Esses modelos mascararam algumas das palavras dos tokens de entrada fornecidos e executaram no lado bidirecional para os tokens de entrada. As técnicas de MLM têm a vantagem de desempenho bidirecional, mas 15% dos tokens de entrada são mascarados, reduzindo a quantidade aprendida de cada frase.\n",
        " ELECTRA usa um novo método de pré-treinamento, chamado de detecção de token substituído (RTD), que treina um modelo bidirecional (como um MLM) enquanto aprende a partir de todas as posições de entrada (como um LM). Inspirado por redes adversárias geradoras (GANs), a ELECTRA treina o modelo para entender a diferença entre dados de entrada “reais” e “falsos”. \n",
        " Neste método, em vez de alterar alguns tokens de entrada substituindo tokens por “[MÁSCARA]” como no BERT, os tokens de entrada substituem alguns tokens de entrada incorretos, provavelmente podemos chamar tokens falsos. Por exemplo, na frase \"Rahul anda de bicicleta nova\", o token de \"bicicleta\" é substituído pelo token de \"bicicleta\".\n",
        "   No método de detecção de token substituído (RTD), os tokens de substituição vêm de outra rede neural chamada gerador, que substitui o token mascarado por tokens “falsos”. O gerador pode ser qualquer pequeno modelo de linguagem mascarada (MLM) que é treinado em conjunto com outro modelo chamado Discriminador. Modelos discriminadores foram estruturados como GAN (redes adversárias geradoras).\n",
        "     O gerador e o discriminador compartilham os mesmos embeddings de palavras de entrada. Durante o pré-treinamento o modelo treina ao máximo com gerador devido à dificuldade de aplicar o modelo GAN ao texto. Após o pré-treinamento, o gerador é removido e apenas faz o ajuste fino do discriminador (o modelo ELECTRA). \n",
        "     Ele melhora consideravelmente em relação aos métodos anteriores ao usar menos de 25% do orçamento de computação, com desempenho comparável ao RoBERTa e XLNet. Os modelos ELECTRA pequenos podem treinar rapidamente em uma GPU. Os modelos ELECTRA alcançam resultados de última geração nas respostas a perguntas SQuAD.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HehC7UEBxXk"
      },
      "source": [
        "Carrego as Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7wWYfAQ2jhW"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "xKbWqIX6PJgu"
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so-I6dJ8LE7b"
      },
      "source": [
        "#2.1 Importar a base de Perguntas, Limitando a 5000 linhas iniciais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7ReY4ZofbIB"
      },
      "source": [
        "# Load Data\n",
        "df=pd.read_excel('3 colunas de PERGUNTA.xlsx', usecols = \"A,C:C\")\n",
        "df= df.rename(columns={'Texto da Pergunta': 'Pergunta'})\n",
        "df= df.rename(columns={'Codigo da Pergunta': 'Codigo'})\n",
        "df= df[:5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgvp89J9B34b"
      },
      "source": [
        "cabeçalho"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8OhMK9XeDgm"
      },
      "source": [
        "#Examinando a Importação\n",
        "#Observar que toda pergunta possui um código unico, oriundo da base de dados.\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nbSaLcZyM6s"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false,
        "id": "BtfvCXinPJgy"
      },
      "source": [
        "df.tail(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "11317c6e054b4c596c16aff329af629e4939a5a9",
        "_cell_guid": "fc76f9c9-1c5a-4963-b3a9-50fd7db6746f",
        "trusted": false,
        "id": "WvV2iXFNPJg0"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29TSlIOdBOL"
      },
      "source": [
        "#2.2 Análise Exploratória dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_t6rBjpraoL"
      },
      "source": [
        "#Há muita incidência de perguntas em Caixa alta e caixa baixa.\n",
        "print(df.Pergunta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj8k3xyRCXzT"
      },
      "source": [
        "##2.2.1 Transformar a coluna em análise Pergunta para minusculo, eliminar os valores nulos, stopwords, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75IKQrzbhqfg"
      },
      "source": [
        "auxiliar = df['Pergunta'].str.lower()\n",
        "df['Pergunta']= auxiliar\n",
        "df.head(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qxrljs2qxFr"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyjmXCfTpdWh"
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    try:\n",
        "      nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    except:\n",
        "      print(input_str)\n",
        "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "    return str(only_ascii)\n",
        "\n",
        "auxiliar = [remove_accents(sentence).replace('b\\'','') for sentence in df['Pergunta']]\n",
        "auxiliar2 = [sentence.replace('\\'','') for sentence in auxiliar]\n",
        "df['Pergunta']= auxiliar2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXGehX0drJGx"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX4VGwykzk0R"
      },
      "source": [
        "todas_stopwords = stopwords.words('portuguese')\n",
        "todas_stopwords.append('para')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrCf_r8SkqDY"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "# inserir nova stopword\n",
        "# stopwords.append('existe')\n",
        "print(stopwords.words('portuguese'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5v1C238fiaE"
      },
      "source": [
        "#2.3 Para o caso de bag of words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxb8LkWTu-LU"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# https://stackoverflow.com/questions/8897593/how-to-compute-the-similarity-between-two-text-documents\n",
        "vect = TfidfVectorizer(min_df=1, stop_words=todas_stopwords)\n",
        "tfidf = vect.fit_transform(df['Pergunta'][:5000])\n",
        "pairwise_similarity = tfidf * tfidf.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zXO0VZxNncm"
      },
      "source": [
        "#2.4 Estamos buscando os pares de pergunta similares, de acordo com o cálculo das diferenças entre os cosenos, buscando um limiar adequado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDAQVR6LvoKn"
      },
      "source": [
        "pairwise_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_QUvyygwL4v"
      },
      "source": [
        "pd.DataFrame(pairwise_similarity.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhyCgIf00bAM"
      },
      "source": [
        "#Armazenando o resultado em um Array\n",
        "resultado = pd.DataFrame(pairwise_similarity.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoDUX0k2P3WG"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rWg_TxJ_mfs"
      },
      "source": [
        "print (resultado)\n",
        "  \n",
        "#?? print (\"\\nclipped arr1 : \\n\", stats.threshold(resultado, threshmin = 0.7 , threshmax = 1, newval = 0.85))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpIDt-Ui0mzr"
      },
      "source": [
        "resultado.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t21GJAHWB_l4"
      },
      "source": [
        "resultado.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ozCKpcsxEO6"
      },
      "source": [
        "#Estamos testando alguns pares identificados nos passos anteriores.\n",
        "df['Pergunta'][19], df['Pergunta'][3127],df['Pergunta'][3364],df['Pergunta'][3779],df['Pergunta'][3914]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D7uiARAfBHI"
      },
      "source": [
        "## 2.4.1 Definimos um valor de threshold para classificar como semelhante.\n",
        "### Proposta daqui em diante, apenas manter a análise exploratória das semelhanças ou Remover as perguntas semelhantes do conjunto de 5000 referente a amostra do Banco de perguntas, mas no entanto a opção desta prova de conceito é justamente a de validamos que a utilização dos métodos de NLP podem contribuir para o saneamento de duplicidades em contexto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjSlUiz_yynE"
      },
      "source": [
        "#Comentário:\n",
        "#resultado[(resultado > 0.99)].any(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5S5JWDYf_rE"
      },
      "source": [
        "##2.4.2 Identificação dos pares de perguntas similares:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8VhRuZ2uDh1"
      },
      "source": [
        "to_drop = []\n",
        "par_perguntas =[]\n",
        "\n",
        "for column in resultado.columns:\n",
        " for index in resultado.index:\n",
        "  if resultado.loc[index, column] > 0.95 and index != column:\n",
        "   to_drop.append([index,column])\n",
        "   par_perguntas.append([df['Pergunta'][index],df['Pergunta'][column]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYXDJBugwfKp"
      },
      "source": [
        "#Identificamos (1110/2) 555 pares com semelhança de 0.95, sugerindo que sejam removidas do banco por duplicidade.\n",
        "len(to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKfH3lE3vDCr"
      },
      "source": [
        "#Identificando os pares\n",
        "print(to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsvg9q9L7g6V"
      },
      "source": [
        "to_drop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SXOGqBD7SEp"
      },
      "source": [
        "par_perguntas[55]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLCK0BUWyhoD"
      },
      "source": [
        "#Identificação textual dos pares de perguntas similares\n",
        "par_perguntas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-jI-8dfxSJH"
      },
      "source": [
        "#identificação textual pontual entre pares\n",
        "df['Pergunta'][3779],df['Pergunta'][3914]\n",
        "                                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ-O6mUEyy6u"
      },
      "source": [
        "#3.Segunda parte do trabalho abordará a busca da similaridade entre as perguntas utilizando o modelo BERT para comparar os resultados de encontrados anteriormente na proposta  da etapa de Bag of words.\n",
        "##Utilizaremos ainda o modelo ELECTRA como alternativa de busca de similaridades entre as perguntas do banco de perguntas.\n",
        "##Aplicação de modelo transformer para similaridade\n",
        "\n",
        " http://www.JohnSnowLabs.com\n",
        "\n",
        " https://github.com/JohnSnowLabs/spark-nlp\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IY-hO7cFZFN"
      },
      "source": [
        "import os\n",
        "! apt-get update -qq > /dev/null   \n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "!pip install nlu  pyspark==2.4.7 > /dev/null   \n",
        "\n",
        "import nlu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0Ig16e_IKPq"
      },
      "source": [
        "# 3.1 Carregar o dataset de Perguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Je4aNEIi4y"
      },
      "source": [
        "## 3.1.1 Estamos alterando os nomes da coluna para manter a compatibilidade com o Modelo proposto para o BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNSSUWT9IFGR"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load dataset to Pandas\n",
        "df= pd.read_excel('3 colunas de PERGUNTA.xlsx', usecols = \"A,C:C\")\n",
        "df= df.rename(columns={'Texto da Pergunta': 'Title'})\n",
        "df= df.rename(columns={'Codigo da Pergunta': 'Id'})\n",
        "df= df[:5000]\n",
        "max_r = 5000\n",
        "df = df.iloc[0:max_r]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3CDRJ5-I27w"
      },
      "source": [
        "auxiliar = df['Title'].str.lower()\n",
        "df['Title']= auxiliar\n",
        "df.head(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nml3wQ1gJCnE"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehbi2aMuJJLF"
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    try:\n",
        "      nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    except:\n",
        "      print(input_str)\n",
        "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "    return str(only_ascii)\n",
        "\n",
        "auxiliar = [remove_accents(sentence).replace('b\\'','') for sentence in df['Title']]\n",
        "auxiliar2 = [sentence.replace('\\'','') for sentence in auxiliar]\n",
        "df['Title']= auxiliar2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lek-LWQ6JThv"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "todas_stopwords = stopwords.words('portuguese')\n",
        "todas_stopwords.append('para')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUXDIQk1Jco5"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "# inserir nova stopword\n",
        "# stopwords.append('existe')\n",
        "print(stopwords.words('portuguese'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbavvKODJsBt"
      },
      "source": [
        "# 3.2. Incorporar perguntas com embeddings de frases de BERT \n",
        "\n",
        "Podemos incorporar o título ou o corpo da pergunta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjrlgUdUJxIB"
      },
      "source": [
        "pipe = nlu.load('embed_sentence.bert')\n",
        "#pipe = nlu.load('albert bert elmo electra xlnet pos')\n",
        "predictions = pipe.predict(df.Title, output_level='document')\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4w1lQqSKAFi"
      },
      "source": [
        "predictions.iloc[0,2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YS_SuvlK2cX"
      },
      "source": [
        "predictions.iloc[0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuUVWHw6LRTf"
      },
      "source": [
        "# 3.3 Como encontrar N sentenças mais semelhantes em um conjunto de dados para uma determinada sentença no conjunto de dados usando BERT\n",
        "Frases com pequenas distâncias entre seus embeddings serão consideradas semelhantes entre si."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVK0-QAsLUsY"
      },
      "source": [
        "## Calculando a  dinstancia entre todos pares de perguntas no DF\n",
        "e_col = 'sentence_embedding_bert'\n",
        "\n",
        "def get_sim_df_for_iloc(sent_iloc, predictions=predictions,e_col=e_col, pipe=pipe):\n",
        "  # Esta função calcula as distâncias de uma frase nas previsões [sent_iloc] para todas as outras frases nas previsões usando a incorporação definida por e_col \n",
        "  # colocando os Embeddings em uma Matriz\n",
        "  embed_mat = np.array([x for x in predictions[e_col]])\n",
        "  # Calcula a distância entre cada par de Embedding\n",
        "  sim_mat = cosine_similarity(embed_mat,embed_mat)\n",
        "  print(\"Perguntas semelhantes a : \" + df.iloc[sent_iloc].Title)\n",
        "  # escreve os scores entre os pares\n",
        "  df['sim_score'] = sim_mat[sent_iloc]\n",
        "  return df \n",
        "sentence_to_compare=  19\n",
        "\n",
        "\n",
        "sim_df_for_one_sent = get_sim_df_for_iloc(sentence_to_compare,predictions,e_col)\n",
        "sim_df_for_one_sent = sim_df_for_one_sent[sim_df_for_one_sent['sim_score']>0.97]\n",
        "sim_df_for_one_sent.sort_values('sim_score', ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Y25Zq6naxq"
      },
      "source": [
        "to_drop_bert=[]\n",
        "par_perguntas_bert=[]\n",
        "\n",
        "for line in range(len(sim_df_for_one_sent)):\n",
        "  sim_df_for_one_sent = get_sim_df_for_iloc(line,predictions,e_col)\n",
        "  for lineToCheck in range(len(sim_df_for_one_sent)):\n",
        "    if sim_df_for_one_sent['sim_score'][lineToCheck] > 0.99:\n",
        "      to_drop_bert.append([line,lineToCheck])\n",
        "      par_perguntas_bert.append([predictions['document'][line], sim_df_for_one_sent['Title'][lineToCheck]])\n",
        "\n",
        "to_drop_bert\n",
        "#sim_df_for_one_sent\n",
        "sim_df_for_one_sent.sort_values('sim_score', ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qopL6QMOtex"
      },
      "source": [
        "# 3.4 Função de plotagem para traçar a distância entre uma frase no conjunto de dados e todas as outras frases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOmifdqcOvy5"
      },
      "source": [
        "def viz_sim_df_for_one_sent( sent_iloc=0, N = 514, sim_df_for_one_sent=sim_df_for_one_sent):\n",
        "  # Representa as N sentenças mais semelhantes em nosso dataframe para a sentença na posição sent_iloc\n",
        "  sim_df_for_one_sent = get_sim_df_for_iloc(sent_iloc)\n",
        "  \n",
        "  sim_df_for_one_sent.index = sim_df_for_one_sent.Title\n",
        "  sent = sim_df_for_one_sent.iloc[sent_iloc].Title\n",
        "  ax = sim_df_for_one_sent.sort_values('sim_score', ascending = False).iloc[:N].sim_score.plot.barh(title=f'As {N} frases mais semelhantes em nosso conjunto de dados para a pergunta \\ n\"{sent}\"', figsize=(40, 30))\n",
        "  ax.set_xlim(0.8, 1)\n",
        "\n",
        "# Basta inserir qualquer número e obter o gráfico de semelhanças da frase em df.iloc [i]\n",
        "# No caso escolhemos a mesma pergunta do título 2.3\n",
        "viz_sim_df_for_one_sent(19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn3vjmJFPdce"
      },
      "source": [
        "#3.5 Calcular cada pontuação de similaridade entre cada frase no dataframe de entrada em pares e gere a matriz de similaridade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbxOxAFpPuHq"
      },
      "source": [
        "def get_sim_df_total( predictions,e_col, string_to_embed,pipe=pipe):\n",
        "  # Esta função calcula as distâncias entre cada par de perguntas. Cria para sempre a frase uma nova coluna com o nome igual à frase com a qual ela se compara\n",
        "\n",
        " \n",
        "  # Colocando os Embeddings em uma Matriz\n",
        "  embed_mat = np.array([x for x in predictions[e_col]])\n",
        "  # calcular a distância entre cada par de embedding\n",
        "  sim_mat = cosine_similarity(embed_mat,embed_mat)\n",
        "  # for i,v in enumerate(sim_mat): predictions[str(i)+'_sim'] = sim_mat[i]\n",
        "  for i,v in enumerate(sim_mat): \n",
        "    s = predictions.iloc[i].document\n",
        "    predictions[s] = sim_mat[i]\n",
        "\n",
        "  return predictions \n",
        "sim_matrix_df = get_sim_df_total(predictions,'sentence_embedding_bert', sentence_to_compare )\n",
        "sim_matrix_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg63NNLDP9Tg"
      },
      "source": [
        "#3.6 Plotar mapa de calor da matriz de similaridade para as primeiras N perguntas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUeaWSQvQJaj"
      },
      "source": [
        "non_sim_columns  = ['text','document','sentence_embedding_bert']\n",
        "\n",
        "def viz_sim_matrix_first_n(num_sentences=5, sim_df = sim_matrix_df):\n",
        "  # Plotar mapa de calor para as primeiras num_sentences\n",
        "  fig, ax = plt.subplots(figsize=(20,10)) \n",
        "  sim_df.index = sim_df.document\n",
        "  sim_columns = list(sim_df.columns)\n",
        "  for b in non_sim_columns : sim_columns.remove(b)\n",
        "  # sim_matrix_df[sim_columns]\n",
        "  ax = sns.heatmap(sim_df.iloc[:num_sentences][sim_columns[:num_sentences]]) \n",
        "\n",
        "  ax.axes.set_title(f\"Matriz de Similaridade para as {num_sentences} sentenças no dataset\",)\n",
        "\n",
        "viz_sim_matrix_first_n()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xr_UVMlRMQW"
      },
      "source": [
        "#3.7 Plotar mapa de calor da matriz de similaridade para as perguntas entre starT_iloc e end_iloc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9WVHiGdRQs5"
      },
      "source": [
        "def viz_sim_matrix_from_to(start_iloc,end_iloc, sim_df = sim_matrix_df):\n",
        "  # Plotar matriz térmica para sentenças em df.iloc [início: fim]   \n",
        "  fig, ax = plt.subplots(figsize=(50,30)) \n",
        "  sim_df.index = sim_df.document\n",
        "  sim_columns = list(sim_df.columns)\n",
        "  for b in non_sim_columns : sim_columns.remove(b)\n",
        "\n",
        "\n",
        "  ax = sns.heatmap(sim_df.iloc[start_iloc:end_iloc][sim_columns[start_iloc:end_iloc]]) # +2 because first 2 cols are not sim_scores\n",
        "\n",
        "  ax.axes.set_title(f\"Matriz de similaridade para as perguntas nas posições df.iloc[{start_iloc}:{end_iloc}] no dataset\",)\n",
        "\n",
        "viz_sim_matrix_from_to(10,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVrgrCJ_RqZX"
      },
      "source": [
        "#3.8 Encontrar as N perguntas mais semelhantes em um conjunto de dados para uma nova pergunta que não existe nos dados usando BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKl1yp3mRxe7"
      },
      "source": [
        "def get_sim_df_for_string(predictions,e_col, string_to_embed,pipe=pipe):\n",
        "  # Cria um Dataframe que tem uma coluna sim_score que descreve a semelhança com a variável string_to_embed\n",
        "\n",
        "  # colocar vetores de predições na matriz\n",
        "  embed_mat = np.array([x for x in predictions[e_col]])\n",
        "\n",
        "  # inserir string de entrada\n",
        "  embedding = pipe.predict(string_to_embed).iloc[0][e_col]\n",
        "\n",
        "  # Replicar incorporação para string de entrada\n",
        "  m = np.array([embedding,]*len(df))\n",
        "  sim_mat = cosine_similarity(m,embed_mat)\n",
        "\n",
        "  #write sim score\n",
        "  df['sim_score'] = sim_mat[0]\n",
        "\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3kKwXU2R4aD"
      },
      "source": [
        "question = ' contribui para o seguro social?'\n",
        "sim_df = get_sim_df_for_string(predictions,'sentence_embedding_bert', 'existe ASO disponivel' )\n",
        "ax = sim_df.sort_values('sim_score', ascending = False).iloc[:20][['sim_score','Title']].plot.barh(title = f\"Frases mais semelhantes para pergunta\\n'{question}'\", figsize=(40,32))\n",
        "ax.set_xlim(0.8, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQYOhfnOSkf8"
      },
      "source": [
        "#3.9 Defina a função de plotagem do Helper para representar os resultados da incorporação de uma string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv5Tp6fKSoZs"
      },
      "source": [
        "def viz_sim_df_for_one_sent( question='foi feita a vistoria no andaime', e_col='sentence_embedding_bert', N = 40, sim_df_for_one_sent=sim_df_for_one_sent):\n",
        "  # Plots the N most similar sentences in our dataframe for sentence at position sent_iloc\n",
        "  sim_df = get_sim_df_for_string(predictions,e_col,question )\n",
        "  sim_df.index = sim_df.Title\n",
        "  sim_df.sort_values('sim_score', ascending = False).iloc[:N][['sim_score','Title']].plot.barh(title = f\"Most similar Sentences for sentence\\n'{question}'\", figsize=(20,14))\n",
        "  ax.set_xlim(0.8, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb7a3WZcS_7C"
      },
      "source": [
        "question = 'contribui para o seguro social?'\n",
        "e_col = 'sentence_embedding_bert'\n",
        "viz_sim_df_for_one_sent(question,e_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_04UlMceTReV"
      },
      "source": [
        "viz_sim_df_for_one_sent('seguro social?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3v86nAJGuIX"
      },
      "source": [
        "# 3.10 Multi Embedding Similarity, encontre as N perguntas mais semelhantes em um conjunto de dados para uma nova frase usando BERT, USE, Electra\n",
        "\n",
        "Primeiro, vamos carregar 3 embeddings ao mesmo tempo e incorporar o texto em nosso conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhqKnY_IGzgJ"
      },
      "source": [
        "multi_pipe = nlu.load('use en.embed_sentence.electra embed_sentence.bert')\n",
        "multi_embeddings = multi_pipe.predict(df.Title,output_level='document')\n",
        "# multi_embeddings = multi_pipe.predict(df.Title)\n",
        "\n",
        "multi_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCohlO1IHDro"
      },
      "source": [
        "#3.11 Cálculo de similaridade de Multi Embeddings\n",
        "\n",
        "\n",
        "Vamos definir uma função que recebe uma string para incorporar, uma lista de embeddings e um pipeline\n",
        "\n",
        "get_sim_df_for_string_multi () calcula todos os embeddings carregados no pipeline NLU de entrada para a string de entrada e calcula as distâncias para cada frase no DF de entrada em todos os embeddings e nos dará uma pontuação normalizada final.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa34XxGtHKA6"
      },
      "source": [
        "def get_sim_df_for_string_multi(predictions,embed_col_names, string_to_embed,pipe=multi_pipe):\n",
        "  # Cria um Dataframe que tem uma coluna sim_score que descreve a semelhança com a variável string_to_embed\n",
        "  #Isso acumula as distâncias de todos os embeddings em embed_col_names e normaliza dividindo por len (embed_col_names)\n",
        "  #faça uma matriz de semelhança vazia que irá armazenar as semelhanças agregadas entre diferentes embeddings\n",
        "  predictions.dropna(inplace=True)\n",
        "  cum_sim = np.zeros((len(predictions),len(predictions)))\n",
        "\n",
        "  # embed with all embedders currently loaded in pipeline\n",
        "  embeddings = pipe.predict(string_to_embed).iloc[0]\n",
        "\n",
        "  #loop over all embeddings columns and accumulate the pairwise distances with string_to_embed into cum_sim\n",
        "  for e_col in embed_col_names:\n",
        "    # get the current embedding for input string\n",
        "    embedding = embeddings[e_col]  \n",
        "    # stack embedding vector for input string\n",
        "    m = np.array([embedding,]*len(predictions)) \n",
        "    # put df vectors in np matrix\n",
        "    embed_mat = np.array([x for x in predictions[e_col]]) \n",
        "    # calculate new similarities\n",
        "    sim_mat = cosine_similarity(m,embed_mat) \n",
        "  # accumulate new simmilarities in cum_sum\n",
        "    cum_sim += sim_mat  \n",
        "\n",
        "  predictions['sim_score'] = cum_sim[0]/len(embed_col_names) \n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfGbnChwI2Yf"
      },
      "source": [
        "question = 'contribui para o seguro social?'\n",
        "col_names = ['sentence_embedding_electra','sentence_embedding_bert', 'sentence_embedding_use']\n",
        "\n",
        "sim_df = get_sim_df_for_string_multi(multi_embeddings,col_names, question )\n",
        "sim_df.index = sim_df.document\n",
        "sim_df.sort_values('sim_score', ascending = False).iloc[:15][['sim_score','document']].plot.barh(title = f\"Most similar Sentences for sentence\\n'{question}'\", figsize=(20,14))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw9m1FA8JQ0U"
      },
      "source": [
        "# 3.12 Defina a função auxiliar para traçar os resultados de similaridade de uma string multiincorporada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjDfhEYBJdGd"
      },
      "source": [
        "def viz_sim_df_for_one_sent_multi_embed( question='Foi feita a vistoria no Guindaste', e_cols=col_names, N = 40, multi_embeddings=multi_embeddings):\n",
        "  # Representa as N sentenças mais semelhantes em nosso dataframe para a sentença na posição sent_iloc\n",
        "  sim_df = get_sim_df_for_string_multi(multi_embeddings,col_names, question )\n",
        "  sim_df.index = sim_df.document\n",
        "  sim_df.sort_values('sim_score', ascending = False).iloc[:N][['sim_score','document']].plot.barh(title = f\"Most similar Sentences for sentence\\n'{question}'\",figsize=(20,14))\n",
        "\n",
        "  ax.set_xlim(0.8, 1)\n",
        "\n",
        "question = 'contribui para o seguro social'\n",
        "col_names = ['sentence_embedding_electra','sentence_embedding_bert', 'sentence_embedding_use']\n",
        "viz_sim_df_for_one_sent_multi_embed(question, col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R5aYw3TKCBT"
      },
      "source": [
        "question = 'seguro social'\n",
        "viz_sim_df_for_one_sent_multi_embed(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7kQErFtKQ-n"
      },
      "source": [
        "question = 'treinamento'\n",
        "viz_sim_df_for_one_sent_multi_embed(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4A3Mx_bOAG8"
      },
      "source": [
        "#4.Conclusões\n",
        "\n",
        "##Os Resultados obtidos segundo a análise por Bag of Words e a posterior comparação com os resultados encontrados nos métodos transformacionais, tanto BERT como ELECTRA, mesmo considerando abordagens diferentes entre os últimos dois métodos, encoraja o processamento de todo o Banco de dados em busca de todas as Similaridades entre as perguntas, considerando que a partir da restrição de 5000 perguntas, conseguimos identificar 555 pares de perguntas e em muitas vezes 3 ou mais similaridades, podemos projetar muito mais pares, ternos, quadras, etc. \n",
        "##Podemos reduzir o banco de perguntas para um tamanho enxugado e sem similaridades. \n",
        "##O objetivo desta prova de conceito não é a de reduzir o tamanho do banco de perguntas, mas indicar a oportunidade de utilização dos métodos de processamento neuro linguísticos para encontrar similaridades de contexto em bancos de informação não otimizados, reduzindo espaço de armazenamento e espaço de busca.\n",
        "\n"
      ]
    }
  ]
}